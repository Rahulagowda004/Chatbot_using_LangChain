{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000015687984190>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000015687985060>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model = \"Gemma2-9b-It\",groq_api_key = groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Rahul, it's nice to meet you! \\n\\nIt's great to know there are other AI Engineers out there. What kind of work do you do as an AI Engineer?  Are you working on any interesting projects right now? \\n\\nI'm always eager to learn more about what people are doing in the field of AI.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 22, 'total_tokens': 96, 'completion_time': 0.134545455, 'prompt_time': 0.000468388, 'queue_time': 0.100693766, 'total_time': 0.135013843}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-070af7be-a7a4-4081-b409-ae67e99df8ce-0', usage_metadata={'input_tokens': 22, 'output_tokens': 74, 'total_tokens': 96})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"hi, my name is rahul and I am a AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Rahul, and you are an AI Engineer!  ðŸ˜Š \\n\\nIs there anything else you'd like to tell me about yourself or your work?  I'm happy to chat.  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 103, 'total_tokens': 150, 'completion_time': 0.085454545, 'prompt_time': 0.003391216, 'queue_time': 0.009324232000000002, 'total_time': 0.088845761}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b8dd2a6c-252e-4316-a768-718b41d47690-0', usage_metadata={'input_tokens': 103, 'output_tokens': 47, 'total_tokens': 150})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"hi, my name is rahul and I am a AI Engineer\"),\n",
    "        AIMessage(content=\"Hello rahul!  it's nice to meet you!  \\n\\nIt's great to know there are other AI Engineers out there. What kind of AI work do you specialize in?  \\n\\nI'm always interested in learning more about how people are using AI to make a difference.\"),\n",
    "        HumanMessage(content=\"Hey what's my name and what do I do\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "###messsage history\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Rahul, it's nice to meet you! \\n\\nIt's great to know you're an AI Engineer. What kind of work do you do in that field?  Are you working on any exciting projects right now?  \\n\\nI'm always interested in learning more about how people are using AI to make a difference.\\n\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hi, my name is rahul and I am a AI Engineer\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Rahul. ðŸ˜Š  \\n\\nI remember that from our first interaction.  \\n\\nIs there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###changing the config----->session id \n",
    "config1 = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name?\")],\n",
    "    config=config1\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are helpful assistant. Answer all the questions to the best of your ability\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Rahul! Nice to meet you.  \\n\\nI'm happy to answer your questions to the best of my ability. What can I do for you today? \\n\\nAs an AI assistant, I can help with things like:\\n\\n* **Generating creative content:**  Stories, poems, articles, dialogue, etc.\\n* **Answering your questions:**  Based on the information I was trained on.\\n* **Summarizing text:**  Give me a long piece of writing and I can provide a shorter version.\\n* **Translating languages:**  I can translate between many different languages.\\n* **And much more!**\\n\\nJust let me know what you need. ðŸ˜Š  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 35, 'total_tokens': 180, 'completion_time': 0.263636364, 'prompt_time': 0.000334299, 'queue_time': 0.013480681, 'total_time': 0.263970663}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e8338bd1-1956-42f5-8fab-c1a0abb0e919-0', usage_metadata={'input_tokens': 35, 'output_tokens': 145, 'total_tokens': 180})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content = \"hi! I'm rahul an AI Engineer \")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Rahul, it's great to meet you! \\n\\nBeing an AI researcher is fascinating work. What areas of AI research are you most interested in?  I'm always eager to learn more about the latest developments in the field.  ðŸ˜Š \\n\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hi, my name is rahul, imma a AI researcher\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Rahul.  ðŸ˜Š  \\n\\nIs there anything else I can help you with today, Rahul?'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name?\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Since you're an AI researcher, Rahul, the possibilities are endless!  \\n\\nHere are some things you could do:\\n\\n* **Continue exploring your current research project:** Are you working on a specific problem or challenge in AI?  Dive deeper into it, analyze data, and experiment with new approaches.\\n* **Learn about new AI techniques and algorithms:** The field is constantly evolving, so staying up-to-date is crucial. Read research papers, attend conferences, and explore online resources.\\n* **Collaborate with other researchers:**  Connect with other AI enthusiasts, share your ideas, and work together on projects. \\n* **Develop new AI applications:** Think about real-world problems that AI could solve and start building solutions.\\n* **Teach and mentor others:** Share your knowledge and passion for AI with students or colleagues.\\n\\nWhat sparks your interest the most right now, Rahul?  I'm happy to brainstorm with you further! ðŸ˜„ \\n\\n\\n\\n\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what do i do\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "managing the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmed  = trim_messages(\n",
    "    max_tokens = 70,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful AI assistant.\"),\n",
    "    HumanMessage(content=\"Hi, my name is Rahul.\"),\n",
    "    AIMessage(content=\"Hello Rahul! How can I assist you today?\"),\n",
    "    HumanMessage(content=\"I'm working on a deep learning project involving RNNs and LSTMs. Can you help me?\"),\n",
    "    AIMessage(content=\"Of course! RNNs and LSTMs are powerful models for sequential data. What part of your project would you like help with?\"),\n",
    "    HumanMessage(content=\"I'm stuck on how to optimize my LSTM model. It's overfitting.\"),\n",
    "    AIMessage(content=\"To combat overfitting in LSTMs, you can try techniques like adding dropout layers, reducing the complexity of the model, or using regularization. Would you like more details on any of these?\")\n",
    "]\n",
    "\n",
    "trimmed.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Chatbot_using_LangChain\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "d:\\Chatbot_using_LangChain\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rahul\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As an AI, I have no memory of past conversations and no access to any information about you or your projects. To help me understand what you\\'re working on, please tell me more about it! \\n\\nFor example, you could say:\\n\\n* \"I\\'m writing a short story about a robot who learns to feel emotions.\"\\n* \"I\\'m building a website for my photography business.\"\\n* \"I\\'m trying to learn how to code in Python.\"\\n\\n\\nLet me know, and I\\'ll do my best to assist you. ðŸ˜Š\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 118, 'prompt_tokens': 39, 'total_tokens': 157, 'completion_time': 0.214545455, 'prompt_time': 0.000372788, 'queue_time': 0.013585011999999999, 'total_time': 0.214918243}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ba7d639b-b079-4450-bc33-e5c95c37e12e-0', usage_metadata={'input_tokens': 39, 'output_tokens': 118, 'total_tokens': 157})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages = itemgetter(\"messages\")|trimmed)|prompt|model\n",
    "        )\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages+ [HumanMessage(content = \"what project am i working on?\")],\n",
    "    \"languages\":\"english\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
